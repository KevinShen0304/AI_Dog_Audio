#### 資料增加 ####
這部分可能是關鍵，我最後是靠這個加分
原因可能 1.原本資料集資料量不多 2.分類有其他類，需要加入超出原本9類的聲音訓練，應該以家裡聲音為主
3.測試集雜訊很多，但訓練集幾乎都是純音

1. 資料蒐集地方
https://freesound.org/
(資料多，可以用標籤搜尋資料，但下載起來比較雜)
https://annotator.freesound.org/fsd/release/FSD50K/
(有分類，但仍要一個一個載)
其他
KAGGLE上分類好的資料集(這部分我載了)

2. 用目前測試集資料(30000筆)
挑出預測不佳的，手動標記，進行訓練

實際做法:
先用現成1400筆訓練集訓練好的模型，預測增加的資料集，預測準的則OK，反之則標記後加到訓練集裡面
隱憂:可看出1400筆訓練集的資料很純，高雜音的加入後如果再資料增強不知道會不會偏離


#### 其他類處理 ####
想法:
最後激活函數使用sigmiod，loss使用binary_crossentropy，取代原有softmax(才不會強制把100%分給10類)
如果所有分類都很低分的話，大概率是其他類，用此機率調整最後結果
實際使用:
高雜音的資料如果沒預測好，會被歸到其他類，最後總分降低


#### 增強學習 ####
最後決賽會模擬AI落地，是希望模型可以依狀況調整，每傳一筆資料與解答同時調整模型
我目前查關鍵字是"增強學習"，但實際運作起來不確定效果
最簡單的方法就是，依照預測結果給5個模型不同權重(越準權重越大)


#### 其他 ####
調整模型架構
多模型合奏



